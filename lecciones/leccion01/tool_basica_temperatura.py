#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Tool MUY BÃSICA que usa script_pronostico_temperatura.py
"""

import ollama
import subprocess
import json

# 1ï¸âƒ£ DEFINIR LA TOOL (lo que lee el LLM)
TOOL_DEFINITION = {
    'type': 'function',
    'function': {
        'name': 'obtener_temperatura',
        'description': 'Obtiene el pronÃ³stico de temperatura para una ciudad espaÃ±ola',
        'parameters': {
            'type': 'object',
            'properties': {
                'ciudad': {
                    'type': 'string',
                    'description': 'Nombre de la ciudad espaÃ±ola (ej: Madrid, Barcelona)'
                }
            },
            'required': ['ciudad']
        }
    }
}

# 2ï¸âƒ£ FUNCIÃ“N que ejecuta el script Python
def ejecutar_script_temperatura(ciudad):
    """
    Ejecuta script_pronostico_temperatura.py y devuelve el resultado
    """
    print(f"\nğŸ”§ [TOOL] Ejecutando script para: {ciudad}")
    
    try:
        # Ejecutar el script Python
        resultado = subprocess.run(
            ['python3', 'script_pronostico_temperatura.py', ciudad],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        if resultado.returncode == 0:
            return resultado.stdout
        else:
            return f"Error al obtener temperatura: {resultado.stderr}"
            
    except Exception as e:
        return f"Error ejecutando script: {str(e)}"

# 3ï¸âƒ£ CHAT con el LLM
def chat_con_tools():
    print("="*60)
    print("ğŸ¤– CHAT CON TOOL BÃSICA DE TEMPERATURA")
    print("="*60)
    print("Escribe 'salir' para terminar\n")
    
    mensajes = [
        {
            'role': 'system',
            'content': 'Eres un asistente que puede consultar el pronÃ³stico de temperatura de ciudades espaÃ±olas usando herramientas.'
        }
    ]
    
    while True:
        # Pedir pregunta al usuario
        pregunta = input("\nğŸ‘¤ TÃº: ").strip()
        
        if pregunta.lower() in ['salir', 'exit', 'quit']:
            print("ğŸ‘‹ Â¡Hasta luego!")
            break
            
        if not pregunta:
            continue
        
        # AÃ±adir mensaje del usuario
        mensajes.append({'role': 'user', 'content': pregunta})
        
        # ğŸ”¹ Primera llamada: LLM decide si usa la tool
        print("\nğŸ¤” Pensando...")
        respuesta = ollama.chat(
            model='llama3.2:3b',
            messages=mensajes,
            tools=[TOOL_DEFINITION]
        )
        
        # ğŸ”¹ Â¿El LLM quiere usar la tool?
        if respuesta['message'].get('tool_calls'):
            print("âœ… El LLM decidiÃ³ usar la tool")
            
            # Obtener parÃ¡metros que extrajo el LLM
            tool_call = respuesta['message']['tool_calls'][0]
            ciudad = tool_call['function']['arguments']['ciudad']
            
            # Ejecutar el script Python
            resultado_temperatura = ejecutar_script_temperatura(ciudad)
            
            # AÃ±adir la llamada a la tool a los mensajes
            mensajes.append(respuesta['message'])
            
            # AÃ±adir el resultado de la tool
            mensajes.append({
                'role': 'tool',
                'content': resultado_temperatura
            })
            
            # ğŸ”¹ Segunda llamada: LLM procesa el resultado de la tool
            print("ğŸ“ Generando respuesta final...")
            respuesta_final = ollama.chat(
                model='llama3.2:3b',
                messages=mensajes
            )
            
            respuesta_texto = respuesta_final['message']['content']
            
        else:
            # No usÃ³ la tool, respuesta directa
            print("â„¹ï¸  El LLM respondiÃ³ sin usar la tool")
            respuesta_texto = respuesta['message']['content']
        
        # Mostrar respuesta al usuario
        print(f"\nğŸ¤– Asistente: {respuesta_texto}")
        
        # AÃ±adir respuesta a los mensajes
        mensajes.append({'role': 'assistant', 'content': respuesta_texto})

# 4ï¸âƒ£ EJECUTAR
if __name__ == '__main__':
    print("\nâš ï¸  IMPORTANTE: AsegÃºrate de tener script_pronostico_temperatura.py en el mismo directorio\n")
    
    try:
        chat_con_tools()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Chat interrumpido. Â¡Hasta luego!")
    except Exception as e:
        print(f"\nâŒ Error: {e}")
