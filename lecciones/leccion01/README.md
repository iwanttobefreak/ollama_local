Hacemos una pregunta al LLM local:
ollama run llama3.1:8b
```¬øque tiempo va a hacer ma√±ana en Madrid?```
C√≥mo solo es un modelo de leguaje y no tiene conexi√≥n con internet es:
```
Lo siento, pero no tengo acceso a informaci√≥n de tiempo real o actualizada sobre el clima. Sin embargo, puedo
sugerirte algunas formas de obtener la informaci√≥n que buscas
```
Ojo porque si le preguntamos lo mismo a codellama:13b nos responde pero se lo ha inventado:
```ollama run codellama:13b```
```
I can provide you with information about the weather in Madrid, but I cannot predict the future. However, I can
tell you the current weather conditions and forecast for Madrid.

According to data from AEMET (the Spanish National Meteorological Agency), the current weather conditions in
Madrid are:

* Temperature: 15¬∞C (59¬∞F)
* Humidity: 60%
* Wind: 2 km/h (1.2 mph)
* Clouds: Scattered clouds

As for the forecast, AEMET predicts that the weather will be mostly sunny with a high of 22¬∞C (72¬∞F) and a low of
9¬∞C (48¬∞F) on Monday. There is a chance of scattered thunderstorms in the afternoon.

Please note that this information may not reflect the actual weather conditions in Madrid, as weather can change
rapidly and it's always best to check with local authorities or a reliable weather source for the most up-to-date
information.
```
Esto es porque se lo inventa, porque codellama est√° entrenado para usar APIs y generar c√≥digo y entonces se inventa que lo puede conseguir. Si le preguntamos:
```¬øCu√°l es la temperatura exacta AHORA MISMO en Madrid?```
```
No puedo proporcionarte la temperatura exacta en Madrid AHORA MISMO. La informaci√≥n meteorol√≥gica actual se basa
en los datos de las estaciones meteorol√≥gicas, que pueden estar ubicadas en diferentes puntos de la ciudad y puede
haber un delay entre el momento en que se toma la medici√≥n y el momento en que se hace disponible.

Sin embargo, puedo proporcionarte una predicci√≥n de la temperatura para Madrid en funci√≥n de las condiciones
meteorol√≥gicas actuales y previstas. Por ejemplo, si la temperatura en Madrid es de 15¬∞C ahora mismo, podr√≠a
predecirse que suba a 17¬∞C en los pr√≥ximos d√≠as si la temperatura promedio es de 16¬∞C durante el d√≠a y baja a 9¬∞C
por la noche.

Por favor, tenga en cuenta que estas son solo predicciones y que la temperatura real puede variar seg√∫n las
condiciones meteorol√≥gicas espec√≠ficas y locales.
```
Para conectar a internet y usar herramientas externas usamos las tools.
Primero generamos un script con python que sea capaz de darnos informaci√≥n. Por ejemplo el script **script_pronostico_temperatura.py** que le pasas como par√°metro la ciudad y los d√≠as y te da el pron√≥stico
Para ver como ejecutarlo, lo ejecutyamos sin par√°metros:
```python script_pronostico_temperatura.py```

Si queremos sacar el pron√≥stico de Barcelona de los siguientes 3 d√≠as ejecutamos:
```python pronostico_temperatura.py Barcelona 7 ```

Ahora vamos a integrar este script de python con una tool que sea capaz de ejecutar ollama.

La estructura b√°sica de una tool definition sigue este formato:

```python
TOOL_DEFINITION = {
    'type': 'function',
    'function': {
        'name': 'obtener_pronostico_temperatura',
        'description': 'SOLO usar cuando el usuario pregunta espec√≠ficamente por el TIEMPO, CLIMA, TEMPERATURA, LLUVIA o PRONOSTICO meteorol√≥gico de una ciudad ESPA√ëOLA. Funciona con CUALQUIER ciudad de Espa√±a. NO usar para otras preguntas generales.',
        'parameters': {
            'type': 'object',
            'properties': {
                'ciudad': {
                    'type': 'string',
                    'description': 'Nombre de CUALQUIER ciudad espa√±ola (Madrid, Barcelona, Matar√≥, Alcobendas, pueblos peque√±os, etc.)'
                },
                'dias': {
                    'type': 'integer',
                    'description': 'D√≠as de pron√≥stico (1-16). Default: 3',
                    'default': 3,
                    'minimum': 1,
                    'maximum': 16
                }
            },
            'required': ['ciudad']
        }
    }
}
```

### üîç Componentes clave:

- **üìñ `description`**: Lo que lee el LLM para decidir **cu√°ndo** usar la funci√≥n
- **‚öôÔ∏è `parameters`**: Qu√© par√°metros extrae el LLM de la petici√≥n del usuario
- **‚ùó `required`**: Par√°metros obligatorios para el funcionamiento de la tool

El LLM decide "quiero usar esta tool con estos par√°metros" y devuelve un json que lo ejecuta el script de python que est√° escrito debajo de la **TOOL_DEFINITION**.

```
# Funci√≥n que ejecuta el script
def obtener_temp(ciudad):
    resultado = subprocess.run(
        ['python3', 'script_pronostico_temperatura.py', ciudad],
        capture_output=True,
        text=True
    )
    return resultado.stdout

# Chat
mensajes = [{'role': 'system', 'content': 'Asistente con acceso a herramientas meteorol√≥gicas.'}]

while True:
    pregunta = input("\nChat: ").strip()

    mensajes.append({'role': 'user', 'content': pregunta})

    # Primera llamada: LLM decide
    respuesta = ollama.chat(model='llama3.1:8b', messages=mensajes, tools=[TOOL])

    # ¬øUs√≥ la tool?
    if respuesta['message'].get('tool_calls'):
        ciudad = respuesta['message']['tool_calls'][0]['function']['arguments']['ciudad']
        resultado = obtener_temp(ciudad)

        mensajes.append(respuesta['message'])
        mensajes.append({'role': 'tool', 'content': resultado})

        # Segunda llamada: LLM procesa resultado
        respuesta = ollama.chat(model='llama3.1:8b', messages=mensajes)

    print(f"Asistente: {respuesta['message']['content']}")
    mensajes.append({'role': 'assistant', 'content': respuesta['message']['content']})
```




---

## ü§ñ Configuraci√≥n del System Prompt

Para definir m√°s exactamente c√≥mo debe actuar el agente, podemos a√±adir instrucciones espec√≠ficas al system prompt:

```python
messages = [
    {
        'role': 'system',
        'content': '''Eres un asistente √∫til con acceso a herramientas meteorol√≥gicas para Espa√±a.

IMPORTANTE:
- Cuando uses herramientas, SIEMPRE presenta los resultados obtenidos de forma clara
- NO digas "no tengo acceso a informaci√≥n" si ya obtuviste datos de herramientas
- Si te preguntan por VARIAS ciudades, usa la herramienta VARIAS VECES (una por ciudad)
- Para comparaciones (ej: "¬ød√≥nde har√° m√°s calor, en X o Y?"), llama a la herramienta para CADA ciudad y luego compara los resultados'''
    }
]
```

---

## üîç Palabras Clave para Activar la Tool

Lista de keywords que ayudan a detectar cu√°ndo el usuario necesita informaci√≥n meteorol√≥gica:

```python
KEYWORDS = [
    'temperatura', 'tiempo', 'clima', 'lluvia', 'viento',
    'pronostico', 'pron√≥stico', 'calor', 'frio', 'fr√≠o',
    'grados', 'soleado', 'nublado', 'despejado', 'meteorolog',
    'nevar', 'nieve', 'tormenta', 'cielo',
    'semana', 'hoy', 'ma√±ana', 'har√°', 'estar√°'
]
```

### üí° Prop√≥sito de las keywords:
- **üéØ Detecci√≥n autom√°tica** de intenciones del usuario
- **‚ö° Activaci√≥n r√°pida** de la tool apropiada
- **üîÑ Filtrado eficiente** de consultas relevantes
