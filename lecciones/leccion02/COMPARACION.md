# ComparaciÃ³n: LecciÃ³n 1 vs LecciÃ³n 2

## Arquitectura Visual

### LecciÃ³n 1: Tools Directas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Script Python                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           Ollama Client                     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚  â”‚  LLM (llama3.2:3b)                 â”‚     â”‚   â”‚
â”‚  â”‚  â”‚  - Recibe pregunta                 â”‚     â”‚   â”‚
â”‚  â”‚  â”‚  - Decide usar tool                â”‚     â”‚   â”‚
â”‚  â”‚  â”‚  - Extrae parÃ¡metros               â”‚     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â”‚                    â†“                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚  â”‚  Tool Definition                   â”‚     â”‚   â”‚
â”‚  â”‚  â”‚  - FunciÃ³n Python local            â”‚     â”‚   â”‚
â”‚  â”‚  â”‚  - subprocess.run()                â”‚     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                    â†“                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Script Externo (script_temperatura.py)     â”‚   â”‚
â”‚  â”‚  - Llama a API Open-Meteo                   â”‚   â”‚
â”‚  â”‚  - Devuelve resultado                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaracterÃ­sticas:**
- âœ… Simple y directo
- âœ… Todo en un solo proceso
- âŒ DifÃ­cil de reutilizar
- âŒ Acoplamiento fuerte

---

### LecciÃ³n 2: MCP Servers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente Python     â”‚         â”‚   Servidor MCP       â”‚
â”‚                      â”‚         â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Ollama Client  â”‚  â”‚  MCP    â”‚  â”‚  MCP Server    â”‚  â”‚
â”‚  â”‚ - LLM decide   â”‚â—„â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  â”‚  - Registra    â”‚  â”‚
â”‚  â”‚ - Usa tools    â”‚  â”‚Protocol â”‚  â”‚    tools       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚  â”‚  - Ejecuta     â”‚  â”‚
â”‚         â†“            â”‚         â”‚  â”‚    lÃ³gica      â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚ MCP Client     â”‚  â”‚         â”‚         â†“            â”‚
â”‚  â”‚ - Conecta      â”‚â—„â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ - Lista tools  â”‚  â”‚         â”‚  â”‚ Script Externo â”‚  â”‚
â”‚  â”‚ - Llama tools  â”‚  â”‚         â”‚  â”‚ - API calls    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Proceso 1                        Proceso 2
```

**CaracterÃ­sticas:**
- âœ… Arquitectura desacoplada
- âœ… MÃºltiples clientes pueden conectarse
- âœ… Protocolo estandarizado
- âœ… Escalable y distribuible
- âš ï¸  MÃ¡s complejo de configurar

---

## ComparaciÃ³n CÃ³digo

### LecciÃ³n 1: Tool Definition

```python
# Todo en un archivo
TOOL_DEFINITION = {
    'type': 'function',
    'function': {
        'name': 'obtener_temperatura',
        'description': '...',
        'parameters': {...}
    }
}

def ejecutar_script_temperatura(ciudad):
    resultado = subprocess.run(['python3', 'script.py', ciudad])
    return resultado.stdout

# Chat loop
respuesta = ollama.chat(model='llama3.2:3b', messages=mensajes, tools=[TOOL_DEFINITION])
if respuesta['message'].get('tool_calls'):
    resultado = ejecutar_script_temperatura(ciudad)
    # Continuar con el resultado...
```

### LecciÃ³n 2: MCP Server + Client

**Servidor (mcp_server_temperatura.py):**
```python
from mcp.server import Server
import mcp.types as types

server = Server("temperatura-server")

@server.list_tools()
async def handle_list_tools() -> list[types.Tool]:
    return [types.Tool(name="obtener_temperatura", ...)]

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict):
    # Ejecutar lÃ³gica
    resultado = subprocess.run(['python3', 'script.py', ciudad])
    return [types.TextContent(text=resultado.stdout)]
```

**Cliente (mcp_client_temperatura.py):**
```python
from mcp import ClientSession
from mcp.client.stdio import stdio_client

async with stdio_client(server_params) as (read, write):
    async with ClientSession(read, write) as session:
        await session.initialize()
        tools = await session.list_tools()
        
        # Usar con Ollama
        respuesta = ollama.chat(model='llama3.2:3b', tools=tools)
        if respuesta['message'].get('tool_calls'):
            resultado = await session.call_tool(tool_name, tool_args)
```

---

## Casos de Uso

### Usa LecciÃ³n 1 (Tools Directas) cuando:
- ğŸ¯ Proyecto simple y personal
- ğŸ¯ Prototipado rÃ¡pido
- ğŸ¯ No necesitas reutilizaciÃ³n
- ğŸ¯ Todo corre en la misma mÃ¡quina

### Usa LecciÃ³n 2 (MCP Servers) cuando:
- ğŸ¯ MÃºltiples clientes/aplicaciones
- ğŸ¯ Herramientas reutilizables
- ğŸ¯ Arquitectura distribuida
- ğŸ¯ Quieres seguir estÃ¡ndares de la industria
- ğŸ¯ Necesitas escalar

---

## Ejemplo PrÃ¡ctico

**Escenario:** Asistente meteorolÃ³gico para toda EspaÃ±a

### Con Tools Directas (LecciÃ³n 1):
```
app_web.py     â†’ Copia de tool_temperatura.py
app_mobile.py  â†’ Copia de tool_temperatura.py
app_cli.py     â†’ Copia de tool_temperatura.py
```
âŒ CÃ³digo duplicado en cada aplicaciÃ³n

### Con MCP Server (LecciÃ³n 2):
```
mcp_server_temperatura.py  (Corre una vez)
         â†‘           â†‘           â†‘
    app_web.py  app_mobile.py  app_cli.py
```
âœ… Un servidor, mÃºltiples clientes

---

## PrÃ³ximos Pasos

1. âœ… Completar LecciÃ³n 1 (entender tools bÃ¡sicas)
2. âœ… Completar LecciÃ³n 2 (entender MCP)
3. ğŸ”œ LecciÃ³n 3: Crear tu propio servidor MCP con mÃºltiples tools
4. ğŸ”œ LecciÃ³n 4: Desplegar MCP servers en producciÃ³n
5. ğŸ”œ LecciÃ³n 5: Integrar con servicios reales (bases de datos, APIs)

---

**Recursos adicionales:**
- [MCP Official Docs](https://modelcontextprotocol.io/)
- [Ollama Tools Documentation](https://ollama.ai/docs)
- [Examples Repository](https://github.com/modelcontextprotocol/servers)
